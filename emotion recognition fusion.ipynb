{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import skimage.io\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "import math\n",
    "import cv2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.applications.ResNet50(input_shape=(224,224,3),include_top=True,weights=None,classes=7)\n",
    "model1.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.load_weights('../input/emotion-util/ResNet_continue.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=True,weights=None,classes=7)\n",
    "model2.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.load_weights('../input/emotion-util/MobileNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.applications.InceptionV3(input_shape=(224,224,3),include_top=True,weights=None,classes=7)\n",
    "model3.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model3.load_weights('../input/emotion-util/InceptionNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = tf.keras.models.load_model('../input/landmark-model/lm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/224-landmarks/feature_extra.csv')\n",
    "test = df[df['Usage']=='PrivateTest'].copy().reset_index()\n",
    "X_img = np.zeros([test.shape[0],224,224])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data \n",
    "(We have saved the result in 224_lanmarks, this step can be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_resize(image, height, width):\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    resized = np.empty([height, width])\n",
    "    x_ratio = float(img_width - 1) / (width - 1) if width > 1 else 0\n",
    "    y_ratio = float(img_height - 1) / (height - 1) if height > 1 else 0\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            x_l, y_l = math.floor(x_ratio * j), math.floor(y_ratio * i)\n",
    "            x_h, y_h = math.ceil(x_ratio * j), math.ceil(y_ratio * i)\n",
    "\n",
    "            x_weight = (x_ratio * j) - x_l\n",
    "            y_weight = (y_ratio * i) - y_l\n",
    "\n",
    "            a = image[y_l, x_l]\n",
    "            b = image[y_l, x_h]\n",
    "            c = image[y_h, x_l]\n",
    "            d = image[y_h, x_h]\n",
    "\n",
    "            pixel = a * (1 - x_weight) * (1 - y_weight) + b * x_weight * (1 - y_weight) +  c * y_weight * (1 - x_weight) + d * x_weight * y_weight\n",
    "\n",
    "            resized[i][j] = pixel\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test.shape[0]):\n",
    "    img= np.array([int(x) for x in test.loc[i]['pixels'].split()]).reshape(48,48)\n",
    "    img = bilinear_resize(img, 224, 224)\n",
    "    X_img[i] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_X(df):\n",
    "    X = np.empty([df.shape[0],176])\n",
    "    for i in range(df.shape[0]):\n",
    "        lm = [float(x) for x in df.loc[i]['relative_lm'].split()][:136]\n",
    "\n",
    "        brow_dis = [float(x) for x in df.loc[i]['brow_distance'].split()]\n",
    "        \n",
    "        eye_dis = [float(x) for x in df.loc[i]['eyes_distance'].split()]\n",
    "\n",
    "        mouth_dis = [float(x) for x in df.loc[i]['mouth_distance'].split()]\n",
    "\n",
    "        mouth_width = [float(df.loc[i]['mouth_width'])]\n",
    "        mouth_height = [float(df.loc[i]['mouth_height'])]\n",
    "        mouth_upward = [float(x) for x in df.loc[i]['mouth_upward'].split()]\n",
    "        \n",
    "        all_feature = lm+brow_dis+eye_dis+mouth_dis+mouth_width+mouth_height+mouth_upward\n",
    "        \n",
    "        X[i,:] = all_feature\n",
    "    return X\n",
    "\n",
    "X_lm = generate_X(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_img.npy',X_img)\n",
    "np.save('X_lm.npy',X_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuse 4 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved test data\n",
    "X_img = np.load(\"../input/224-landmarks/X_img.npy\").astype('uint8') # for image based model\n",
    "X_lm = np.load(\"../input/224-landmarks/X_lm.npy\") # for landmark based model\n",
    "X_img_3 = np.array([cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) for img in X_img]) #change the image from Gray to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_3 = X_img_3/255\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_lm)\n",
    "X_lm = scaler.transform(X_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction result\n",
    "y_pred_1 = model1.predict(X_img_3)\n",
    "y_pred_2 = model2.predict(X_img_3)\n",
    "y_pred_3 = model3.predict(X_img_3)\n",
    "y_pred_4 = model4.predict(X_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because landmark_model and image based model use different label method, here we change the label. \n",
    "y_pred_4 = np.where(y_pred_4 == 4,99, y_pred_4)\n",
    "y_pred_4 = np.where(y_pred_4 == 5,100, y_pred_4)\n",
    "y_pred_4 = np.where(y_pred_4 == 6,4, y_pred_4)\n",
    "y_pred_4 = np.where(y_pred_4 == 99,5, y_pred_4)\n",
    "y_pred_4 = np.where(y_pred_4 == 100,6, y_pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(y_pred_1+y_pred_2+y_pred_3+y_pred_4,axis=1)\n",
    "\n",
    "# because landmark_model and image based model use different label method, here we change the label.\n",
    "Y_test = np.array(test['emotion'])\n",
    "Y_test = np.where(Y_test == 4,99, Y_test)\n",
    "Y_test = np.where(Y_test == 5,100, Y_test)\n",
    "Y_test = np.where(Y_test == 6,4, Y_test)\n",
    "Y_test = np.where(Y_test == 99,5, Y_test)\n",
    "Y_test = np.where(Y_test == 100,6, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction result for 3 classes:\n",
    "# positve: happy, surprise, negative: anger, fear, disgust, sad, neutral\n",
    "y_test_3c =  np.where(Y_test== 1,0,Y_test)\n",
    "y_test_3c =  np.where(y_test_3c== 2, 0,y_test_3c)\n",
    "y_test_3c =  np.where(y_test_3c== 3, 1,y_test_3c)\n",
    "y_test_3c =  np.where(y_test_3c== 4, 2,y_test_3c)\n",
    "y_test_3c =  np.where(y_test_3c== 5, 0,y_test_3c)\n",
    "y_test_3c =  np.where(y_test_3c== 6, 1,y_test_3c)\n",
    "\n",
    "y_pred_3c =  np.where(Y_pred== 1,0,Y_pred)\n",
    "y_pred_3c =  np.where(y_pred_3c== 2, 0,y_pred_3c)\n",
    "y_pred_3c =  np.where(y_pred_3c== 3, 1,y_pred_3c)\n",
    "y_pred_3c =  np.where(y_pred_3c== 4, 2,y_pred_3c)\n",
    "y_pred_3c =  np.where(y_pred_3c== 5, 0,y_pred_3c)\n",
    "y_pred_3c =  np.where(y_pred_3c== 6, 1,y_pred_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate prediction accuracy\n",
    "(y_pred_3c  == y_test_3c).sum()/2579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "cm1 = metrics.confusion_matrix(Y_pred, Y_test)\n",
    "cm_normalized = cm1.astype('float') / cm1.sum(axis=1)[:, np.newaxis]\n",
    "labels = ['anger','disgust','fear','happy','neutral','sad','surprise']\n",
    "# labels = ['negative','positive','nutreul']\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", linewidths=.5, square=True, cmap='Blues',\n",
    "            cbar_kws={\"shrink\": .82},annot_kws={\"size\":20})\n",
    "plt.ylabel('True emotion', size=17,rotation = 90)\n",
    "tick_marks = np.array(range(len(labels))) + 0.5\n",
    "plt.xticks(tick_marks,labels,ha='center',fontsize = 12)\n",
    "plt.yticks(tick_marks,labels,va='center',fontsize = 12)\n",
    "plt.xlabel('Predicted emotion', size=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
